---
title: "Ollama 임베더"
description: "Ollama는 LLM과 임베딩 모델 모두를 실행할 수 있습니다."
---

import { Callout } from "nextra/components";
import Image from "next/image";

<Image
  src="/images/anythingllm-setup/embedder-configuration/local/ollama/header-image.png"
  height={1080}
  width={1920}
  quality={100}
  alt="Ollama 임베더"
/>

# Ollama 임베더

<Callout type="error" emoji="️‼️">
  **주의!**

    Ollama의 `/models` 엔드포인트는 드롭다운 선택에서 LLM과 임베딩 모델을 모두 표시합니다. **임베딩을 위해** 임베딩 모델을 사용하는지 확인하십시오.

예를 들어 **llama2**는 LLM이며 임베더가 아닙니다.

</Callout>

## Ollama에 연결하기

Ollama를 로컬에서 실행할 때 기본 설정을 사용하여 `http://127.0.0.1:11434`로 Ollama에 연결해야 합니다.

[Ollama](https://ollama.com)는 LLM **및** 임베딩 모델을 실행할 수 있습니다.

사용하려는 관련 임베딩 모델을 다운로드하고 온보딩 또는 **설정**에서 선택하여 업로드된 문서를 Ollama를 통해 임베드하세요.

**설정**에서 언제든지 다른 모델로 업데이트할 수 있습니다.

<Image
  src="/images/anythingllm-setup/embedder-configuration/local/ollama/ollama-embedder.png"
  height={1080}
  width={1920}
  quality={100}
  alt="Ollama 임베더"
/>
