---
title: "내 AI 에이전트가 도구를 사용하지 않는 이유!"
description: "AI 에이전트는 LLM의 새로운 사용 사례를 열어주지만 완벽하지는 않습니다. OSS LLM이 도구를 사용하지 않는 일반적인 문제를 읽어보세요."
---

import { Callout } from "nextra/components";
import Image from "next/image";

# 내 `@agent`가 도구를 사용하지 않는 이유!

AI 에이전트는 단순히 텍스트로 응답하는 것 외에도 LLM을 활용하여 **무언가를 할 수 있는** 새로운 방법을 제공합니다. 하지만 이 LLM들은 아직 완전한 지능을 가지지 않았으며, 다른 LLM 구현과 마찬가지로 "함정"이 있습니다.

다른 LLM 문제와 마찬가지로, 이는 주로 사용 중인 모델에 따라 달라지며, 더 강력하고 능력 있는 모델일수록 더 나은 결과를 얻을 수 있습니다. 에이전트를 사용할 때는 실행 가능한 최고의 모델을 사용하는 것이 좋습니다.

_주의_: JSON/함수 호출을 위해 특별히 훈련된 작은 모델도 있지만, 일반 텍스트/명령 모델을 사용하는 것이 일반적입니다.

## 에이전트란 무엇인가요?

너무 기술적이지 않게 설명하자면, "AI 에이전트"가 무엇인지 이해하기 위한 기본 지식이 필요합니다. 아래 그래픽은 LLM들이 무엇을 "추론"하고 있는지를 설명합니다. 보시다시피, 이는 특정 형식의 텍스트 응답과 다르지 않습니다!

<Image
  src="/images/faq/agent-not-using-tools/regular.png"
  height={1080}
  width={1920}
  quality={100}
  style={{ borderRadius: "20px", marginBottom: 10 }}
/>

<Image
  src="/images/faq/agent-not-using-tools/llm.png"
  height={1080}
  width={1920}
  quality={100}
  style={{ borderRadius: "20px" }}
/>

이제 LLM이 프롬프트와 최종 응답 사이에 추가 단계를 수행하고 있다는 것을 알았으니, 에이전트 구현이 JSON 생성 부분에서 잘못될 수 있다는 것을 이해할 수 있습니다.

에이전트가 작동하려면 이 파이프라인이 어떻게 작동하는지 이해한 후 문제를 해결하고 디버그하는 방법을 알아보겠습니다.

## 일부 LLM은 JSON 생성에 서툴고 지시를 따르는 데 더 서툽니다.

<Callout type="info" emoji="️💡">
  **팁:**
    클라우드 기반 (비-양자화) 모델은 일반적으로 지시를 따르고 필요한 도구 호출에 맞는 유효한 JSON을 형성하는 데 훨씬 뛰어납니다.

    TeamplGPT에서는 에이전트 호출에만 클라우드 기반 모델을 사용하고 일반 채팅에는 오픈 소스 모델을 사용할 수 있습니다.
</Callout>

에이전트와 관련된 주요 문제는 작은 매개변수 모델을 사용하려는 사람들이 GPT 수준의 도구 상호작용을 기대하는 경우입니다. 아래는 잘못된 도구 호출의 영향을 완화하는 방법과 일반적인 해결책입니다.

## 모델이 도구 호출을 환각합니다.

도구가 실제로 호출될 때 UI에 "생각" 출력이 표시됩니다. 이는 도구가 실제로 호출되었음을 나타냅니다. LLM이 정보를 응답하지만 생각 체인이 보이지 않는 경우, 이는 출력을 만들고 도구를 호출했다고 가장하는 것입니다.

<Image
  src="/images/faq/agent-not-using-tools/thought.png"
  height={1080}
  width={1920}
  quality={100}
  style={{ borderRadius: "20px" }}
/>

### 일반적인 해결책

- 높은 양자화 버전 또는 더 큰 매개변수 모델로 교체
- `/reset` 채팅 기록을 초기화하고 프롬프트 다시 요청

## LLM이 `XYZ` 도구를 호출할 수 없다고 말합니다.

일부 모델은 너무 강하게 정렬되어 특정 도구를 사용하는 것을 거부합니다. 이는 웹사이트 스크래핑과 같은 요청에 일반적입니다.

### 일반적인 해결책

- 높은 양자화 버전, 더 큰 매개변수 모델 또는 덜 제한된 모델로 교체
- `/reset` 채팅 기록을 초기화하고 프롬프트 다시 요청
- 프롬프트 창 크기 감소를 위해 사용하지 않는 도구 비활성화

## LLM이 도구를 전혀 감지하거나 호출하지 않습니다.

오픈 소스 모델은 양자화와 제한된 컨텍스트 창으로 인해 도구를 올바르게 발견하거나 호출하는 것을 거부할 수 있습니다.

도구가 LLM의 프롬프트에 삽입되어 발견 및 실행될 때 정보 과부하가 되거나 양자화로 인해 도구 호출에 필요한 스키마와 정확히 일치하는 유효한 JSON을 생성하지 못할 수 있습니다. LLM은 단순히 JSON을 생성하는데, 낮은 매개변수와 양자화 모델은 특히 이를 잘하지 못합니다!

하지만 TeamplGPT는 약간의 잘못된 JSON을 올바르게 형식화하여 호출이 성공하도록 하는 몇 가지 중요한 수정 작업을 수행하지만, 이 부분에서 할 수 있는 것은 한정적입니다.

### 일반적인 해결책

- 높은 양자화 버전, 더 큰 매개변수 모델 또는 덜 제한된 모델로 교체
- `/reset` 채팅 기록을 초기화하고 프롬프트 다시 요청 (채팅 기록이 JSON 출력에 영향을 미칠 수 있음)
- 프롬프트 창 크기와 부하를 줄이기 위해 사용하지 않는 도구 비활성화
